{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "doxyDonkeyPosts = pd.read_csv('doxyDonkeyPosts.csv', index_col = False)\n",
    "doxyDonkeyPosts = doxyDonkeyPosts['Posts'].values.astype('U')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_df=0.5, min_df=2, stop_words='english')\n",
    "X = vectorizer.fit_transform(doxyDonkeyPosts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization complete\n",
      "Iteration  0, inertia 5331.058\n",
      "Iteration  1, inertia 2703.192\n",
      "Iteration  2, inertia 2693.290\n",
      "Iteration  3, inertia 2688.921\n",
      "Iteration  4, inertia 2687.149\n",
      "Iteration  5, inertia 2686.032\n",
      "Iteration  6, inertia 2685.043\n",
      "Iteration  7, inertia 2684.447\n",
      "Iteration  8, inertia 2683.959\n",
      "Iteration  9, inertia 2683.688\n",
      "Iteration 10, inertia 2683.375\n",
      "Iteration 11, inertia 2683.045\n",
      "Iteration 12, inertia 2682.635\n",
      "Iteration 13, inertia 2681.893\n",
      "Iteration 14, inertia 2681.173\n",
      "Iteration 15, inertia 2680.732\n",
      "Iteration 16, inertia 2680.565\n",
      "Iteration 17, inertia 2680.427\n",
      "Iteration 18, inertia 2680.309\n",
      "Iteration 19, inertia 2680.207\n",
      "Iteration 20, inertia 2680.132\n",
      "Iteration 21, inertia 2680.103\n",
      "Iteration 22, inertia 2680.081\n",
      "Iteration 23, inertia 2680.070\n",
      "Iteration 24, inertia 2680.068\n",
      "Iteration 25, inertia 2680.066\n",
      "Converged at iteration 25: center shift 0.000000e+00 within tolerance 7.339674e-09\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=100,\n",
       "       n_clusters=3, n_init=1, n_jobs=None, precompute_distances='auto',\n",
       "       random_state=None, tol=0.0001, verbose=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km = KMeans(n_clusters=3, init='k-means++', max_iter= 100, n_init=1, verbose=True)\n",
    "km.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2], dtype=int32), array([1638,  686,  480]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(km.labels_, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text={}\n",
    "for i, cluster in enumerate(km.labels_):\n",
    "    oneDocument = doxyDonkeyPosts[i]\n",
    "    if cluster not in text.keys():\n",
    "        text[cluster] = oneDocument\n",
    "    else:\n",
    "        text[cluster] += oneDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from collections import defaultdict\n",
    "from string import punctuation\n",
    "from heapq import nlargest\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "_stopwords = set(stopwords.words('english') + list(punctuation) + ['million', 'billion', 'years', 'millions', 'billions', 'y/y', \"''\", \"``\" \"'s\", \"\\n\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = {}\n",
    "counts = {}\n",
    "for cluster in range(3):\n",
    "    word_sent = word_tokenize(text[cluster].lower())\n",
    "    word_sent = [word for word in word_sent if word not in _stopwords]\n",
    "    freq = FreqDist(word_sent)\n",
    "    keywords[cluster] = nlargest(100, freq, key=freq.get)\n",
    "    counts[cluster] = freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_keys = {}\n",
    "for cluster in range(3):\n",
    "    other_clusters = list(set(range(3)) - set([cluster]))\n",
    "    keys_other_clusters = set(keywords[other_clusters[0]]).union(set(keywords[other_clusters[1]]))\n",
    "    unique = set(keywords[cluster]) - keys_other_clusters\n",
    "    unique_keys[cluster] = nlargest(10, unique, key = counts[cluster].get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ['ads',\n",
       "  'video',\n",
       "  'use',\n",
       "  'products',\n",
       "  'product',\n",
       "  'search',\n",
       "  'apps',\n",
       "  'ad',\n",
       "  'pay',\n",
       "  'even'],\n",
       " 1: ['uber',\n",
       "  'india',\n",
       "  'chinese',\n",
       "  'round',\n",
       "  'capital',\n",
       "  'funding',\n",
       "  'raised',\n",
       "  'investment',\n",
       "  'valuation',\n",
       "  'e-commerce'],\n",
       " 2: ['quarter',\n",
       "  'share',\n",
       "  'profit',\n",
       "  'rose',\n",
       "  'earnings',\n",
       "  'analysts',\n",
       "  'cents',\n",
       "  'per',\n",
       "  'trading',\n",
       "  'fell']}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
