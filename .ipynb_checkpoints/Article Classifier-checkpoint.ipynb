{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "doxyDonkeyPosts = pd.read_csv('doxyDonkeyPosts.csv', index_col = False)\n",
    "doxyDonkeyPosts = doxyDonkeyPosts['Posts'].values.astype('U')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_df=0.5, min_df=2, stop_words='english')\n",
    "X = vectorizer.fit_transform(doxyDonkeyPosts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization complete\n",
      "Iteration  0, inertia 5331.058\n",
      "Iteration  1, inertia 2703.192\n",
      "Iteration  2, inertia 2693.290\n",
      "Iteration  3, inertia 2688.921\n",
      "Iteration  4, inertia 2687.149\n",
      "Iteration  5, inertia 2686.032\n",
      "Iteration  6, inertia 2685.043\n",
      "Iteration  7, inertia 2684.447\n",
      "Iteration  8, inertia 2683.959\n",
      "Iteration  9, inertia 2683.688\n",
      "Iteration 10, inertia 2683.375\n",
      "Iteration 11, inertia 2683.045\n",
      "Iteration 12, inertia 2682.635\n",
      "Iteration 13, inertia 2681.893\n",
      "Iteration 14, inertia 2681.173\n",
      "Iteration 15, inertia 2680.732\n",
      "Iteration 16, inertia 2680.565\n",
      "Iteration 17, inertia 2680.427\n",
      "Iteration 18, inertia 2680.309\n",
      "Iteration 19, inertia 2680.207\n",
      "Iteration 20, inertia 2680.132\n",
      "Iteration 21, inertia 2680.103\n",
      "Iteration 22, inertia 2680.081\n",
      "Iteration 23, inertia 2680.070\n",
      "Iteration 24, inertia 2680.068\n",
      "Iteration 25, inertia 2680.066\n",
      "Converged at iteration 25: center shift 0.000000e+00 within tolerance 7.339674e-09\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=100,\n",
       "       n_clusters=3, n_init=1, n_jobs=None, precompute_distances='auto',\n",
       "       random_state=None, tol=0.0001, verbose=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km = KMeans(n_clusters=3, init='k-means++', max_iter= 100, n_init=1, verbose=True)\n",
    "km.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2], dtype=int32), array([1638,  686,  480]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(km.labels_, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text={}\n",
    "for i, cluster in enumerate(km.labels_):\n",
    "    oneDocument = doxyDonkeyPosts[i]\n",
    "    if cluster not in text.keys():\n",
    "        text[cluster] = oneDocument\n",
    "    else:\n",
    "        text[cluster] += oneDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from collections import defaultdict\n",
    "from string import punctuation\n",
    "from heapq import nlargest\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "_stopwords = set(stopwords.words('english') + list(punctuation) + ['million', 'billion', 'years', 'millions', 'billions', 'y/y', \"''\", \"``\" \"'s\", \"\\n\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = {}\n",
    "counts = {}\n",
    "for cluster in range(3):\n",
    "    word_sent = word_tokenize(text[cluster].lower())\n",
    "    word_sent = [word for word in word_sent if word not in _stopwords]\n",
    "    freq = FreqDist(word_sent)\n",
    "    keywords[cluster] = nlargest(100, freq, key=freq.get)\n",
    "    counts[cluster] = freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_keys = {}\n",
    "for cluster in range(3):\n",
    "    other_clusters = list(set(range(3)) - set([cluster]))\n",
    "    keys_other_clusters = set(keywords[other_clusters[0]]).union(set(keywords[other_clusters[1]]))\n",
    "    unique = set(keywords[cluster]) - keys_other_clusters\n",
    "    unique_keys[cluster] = nlargest(10, unique, key = counts[cluster].get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ['ads',\n",
       "  'video',\n",
       "  'use',\n",
       "  'products',\n",
       "  'product',\n",
       "  'search',\n",
       "  'apps',\n",
       "  'ad',\n",
       "  'pay',\n",
       "  'even'],\n",
       " 1: ['uber',\n",
       "  'india',\n",
       "  'chinese',\n",
       "  'round',\n",
       "  'capital',\n",
       "  'funding',\n",
       "  'raised',\n",
       "  'investment',\n",
       "  'valuation',\n",
       "  'e-commerce'],\n",
       " 2: ['quarter',\n",
       "  'share',\n",
       "  'profit',\n",
       "  'rose',\n",
       "  'earnings',\n",
       "  'analysts',\n",
       "  'cents',\n",
       "  'per',\n",
       "  'trading',\n",
       "  'fell']}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = \"Target has finalized an investment in Casper Sleep, pumping $75 million into the fast-growing mattress startup in a funding round that will total $100 million or more, according to a source familiar with the deal. Existing Casper investors like Lerer Hippeau Ventures, IVP and NEA are also participating in the round. New investors, in addition to Target, could send the round over $100 million. The investment comes after Target and Casper could not come to terms on an outright acquisition after Target offered to buy the startup for $1 billion. Casper, which is known for its foam mattresses that it ships to customers folded up in a box, last raised $55 million at a valuation of around $500 million in the summer of 2015. The startup received a higher valuation with this new investment, though the exact terms could not be learned. For Target, the investment signals a move to put its money where its mouth is in its attempt to reclaim some of the cool factor that made it a hit among discount retailers for so long through relationships with popular designers and brands.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "classifier = KNeighborsClassifier(n_neighbors=10)\n",
    "classifier.fit(X, km.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = vectorizer.transform([article.encode('ascii', errors='ignore')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x13221 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 64 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
